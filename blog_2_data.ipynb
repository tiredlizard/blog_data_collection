{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re  # Importing regex module\n",
    "import random\n",
    "import time\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamesurl = \"https://www.mobygames.com/platform/switch/\"\n",
    "r = requests.get(gamesurl)\n",
    "print(r.status_code)\n",
    "gamesbs = BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "titles = []\n",
    "links = []\n",
    "years = []\n",
    "scores = []\n",
    "genres = []\n",
    "\n",
    "base_url = gamesurl \n",
    "max_pages = 10\n",
    "\n",
    "for page_count in range(0, max_pages + 1):\n",
    "    # Construct URL for each page\n",
    "    if page_count == 0:\n",
    "        page_url = base_url  # First page has no /page:x/\n",
    "    else:\n",
    "        page_url = f\"{base_url}page:{page_count}/\"\n",
    "\n",
    "    print(f\"Requesting URL: {page_url}\")\n",
    "\n",
    "    response = requests.get(page_url)\n",
    "    tables = pd.read_html(StringIO(response.text))  # Get all tables on the page\n",
    "\n",
    "    # Assuming the table you want is the first one (tables[0])\n",
    "    games_df = tables[0]  \n",
    "\n",
    "    # Extract relevant columns from games_df as needed\n",
    "    titles.extend(games_df['Title'].tolist())  # replace 'Title' with the actual column name\n",
    "    years.extend(games_df['Released'].tolist())  # replace 'Year' with the actual column name\n",
    "    scores.extend(games_df['Moby Score'].tolist())  # replace 'Score' with the actual column name\n",
    "    genres.extend(games_df['Genres'].tolist())\n",
    "\n",
    "    # If links are in another structure on the page, BeautifulSoup might still be useful:\n",
    "    gamesbs = BeautifulSoup(response.text, 'html.parser')\n",
    "    game_links = [tag['href'] for tag in gamesbs.select('td.text-nowrap a')]\n",
    "    links.extend(game_links)\n",
    "\n",
    "    page_count += 1\n",
    "    time.sleep(3)  # Respectful delay for scraping\n",
    "\n",
    "print(f\"Collected {len(titles)} titles.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_games = {\n",
    "    'Title': titles,\n",
    "    'Score': scores,\n",
    "    'Year': years,\n",
    "    'Genre': genres\n",
    "}\n",
    "\n",
    "basic_games_df = pd.DataFrame(basic_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_urls = links[:250]\n",
    "\n",
    "# List to store all extracted game data\n",
    "games_data_1 = []\n",
    "\n",
    "# Define the fields you want to extract (e.g., Genre, Perspective, Gameplay, etc.)\n",
    "fields = [\"Perspective\", \"Gameplay\", \"Interface\", \"Setting\"]\n",
    "\n",
    "# Loop through each game URL\n",
    "for url in game_urls:\n",
    "    # Request the HTML content of the page\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Initialize a dictionary to store the extracted data for this game\n",
    "        game_info = {}\n",
    "\n",
    "        ## Extract Release Date (no cleaning applied here)\n",
    "        for dt in soup.select('.info-release dt'):\n",
    "            if dt.text.strip() == \"Released\":\n",
    "                game_info['Released'] = dt.find_next_sibling('dd').text.strip()\n",
    "\n",
    "        ## Extract Critics (no cleaning applied here)\n",
    "        for dt in soup.select('.info-score dt'):\n",
    "            if dt.text.strip() == \"Critics\":\n",
    "                game_info['Critics'] = dt.find_next_sibling('dd').text.strip()\n",
    "\n",
    "        ## Extract other fields and save as raw data (no cleaning)\n",
    "        for field in fields:\n",
    "            for dt in soup.select('.info-genres dt'):\n",
    "                if dt.text.strip() == field:\n",
    "                    game_info[field] = dt.find_next_sibling('dd').text.strip()\n",
    "\n",
    "        ## Extract ESRB Rating (no cleaning applied)\n",
    "        for dt in soup.select('.info-specs dt'):\n",
    "            if dt.text.strip() == \"ESRB Rating\":\n",
    "                game_info['ESRB Rating'] = dt.find_next_sibling('dd').text.strip()\n",
    "\n",
    "        ## Extract Multiplayer Options (no cleaning applied)\n",
    "        for dt in soup.select('.info-specs dt'):\n",
    "            if dt.text.strip() == \"Multiplayer Options\":\n",
    "                game_info['Multiplayer Options'] = dt.find_next_sibling('dd').text.strip()\n",
    "\n",
    "        # Add the game data to the list\n",
    "        games_data_1.append(game_info)\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve {url}\")\n",
    "\n",
    "    # Sleep for a random time between 3 and 5 seconds to avoid being blocked\n",
    "    time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "games_df_1 = pd.DataFrame(games_data_1)\n",
    "\n",
    "# Print the DataFrame (you can clean the data afterwards)\n",
    "print(games_df_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "game_urls = links[250:]\n",
    "\n",
    "# List to store all extracted game data\n",
    "games_data_2 = []\n",
    "\n",
    "# Define the fields you want to extract (e.g., Genre, Perspective, Gameplay, etc.)\n",
    "fields = [\"Perspective\", \"Gameplay\", \"Interface\", \"Setting\"]\n",
    "\n",
    "# Loop through each game URL\n",
    "for url in game_urls:\n",
    "    # Request the HTML content of the page\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Initialize a dictionary to store the extracted data for this game\n",
    "        game_info = {}\n",
    "\n",
    "        ## Extract Release Date (no cleaning applied here)\n",
    "        for dt in soup.select('.info-release dt'):\n",
    "            if dt.text.strip() == \"Released\":\n",
    "                game_info['Released'] = dt.find_next_sibling('dd').text.strip()\n",
    "\n",
    "        ## Extract Critics (no cleaning applied here)\n",
    "        for dt in soup.select('.info-score dt'):\n",
    "            if dt.text.strip() == \"Critics\":\n",
    "                game_info['Critics'] = dt.find_next_sibling('dd').text.strip()\n",
    "\n",
    "        ## Extract other fields and save as raw data (no cleaning)\n",
    "        for field in fields:\n",
    "            for dt in soup.select('.info-genres dt'):\n",
    "                if dt.text.strip() == field:\n",
    "                    game_info[field] = dt.find_next_sibling('dd').text.strip()\n",
    "\n",
    "        ## Extract ESRB Rating (no cleaning applied)\n",
    "        for dt in soup.select('.info-specs dt'):\n",
    "            if dt.text.strip() == \"ESRB Rating\":\n",
    "                game_info['ESRB Rating'] = dt.find_next_sibling('dd').text.strip()\n",
    "\n",
    "        ## Extract Multiplayer Options (no cleaning applied)\n",
    "        for dt in soup.select('.info-specs dt'):\n",
    "            if dt.text.strip() == \"Multiplayer Options\":\n",
    "                game_info['Multiplayer Options'] = dt.find_next_sibling('dd').text.strip()\n",
    "\n",
    "        # Add the game data to the list\n",
    "        games_data_2.append(game_info)\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve {url}\")\n",
    "\n",
    "    # Sleep for a random time between 3 and 5 seconds to avoid being blocked\n",
    "    time.sleep(random.randint(3, 5))\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "games_df_2 = pd.DataFrame(games_data_2)\n",
    "\n",
    "# Print the DataFrame (you can clean the data afterwards)\n",
    "print(games_df_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_games_df = pd.concat([games_df_1, games_df_2], ignore_index=True)\n",
    "combined_games_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean unwanted characters like newline, commas, and slashes\n",
    "def clean_value(value):\n",
    "    return re.sub(r'[\\n,\\/]+', ' ', value).strip()\n",
    "\n",
    "def clean_and_split(value):\n",
    "    \n",
    "    # Remove unwanted characters like newline, commas, and slashes\n",
    "    cleaned_value = re.sub(r'[\\n]+', ' ', value).strip()\n",
    "\n",
    "    # Remove any text in parentheses\n",
    "    cleaned_value = re.sub(r'\\s*\\(.*?\\)', '', cleaned_value)\n",
    "\n",
    "    cleaned_value = re.sub(r'RPG', 'Role-playing', cleaned_value)\n",
    "\n",
    "    # Replace slashes with ampersands\n",
    "    # cleaned_value = cleaned_value.replace('/', '&')\n",
    "\n",
    "    # Add spaces between patterns like \"1st-person3rd-person\" so they can be split\n",
    "    cleaned_value = re.sub(r'(\\d\\w*-person)(?=\\d)', r'\\1 ', cleaned_value)\n",
    "\n",
    "    # Split based on capital letters, spaces, or common delimiters (like slashes)\n",
    "    split_values = re.split(r'(?=[A-Z])|\\s*[,]+\\s*|\\s(?=[0-9])', cleaned_value)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    return [val.strip() for val in split_values if val.strip()]\n",
    "\n",
    "def clean_genres(value):\n",
    "    # Check if value is a string\n",
    "    if isinstance(value, str):\n",
    "\n",
    "        # Split based on commas and remove extra spaces\n",
    "        cleaned_value = [genre.strip() for genre in cleaned_value.split(',')]\n",
    "        \n",
    "        return cleaned_value\n",
    "    return value  \n",
    "\n",
    "def clean_critics(critics):\n",
    "    critics = re.sub(r'\\s?\\(\\d+\\)', '', critics)  # Remove numbers in parentheses\n",
    "    critics = re.sub(r'%', '', critics)  # Remove percentage sign\n",
    "    critics = critics.strip()  # Remove any remaining unwanted whitespace\n",
    "    return critics\n",
    "\n",
    "# Only get month\n",
    "def clean_released_date(value):\n",
    "    return value.split()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split values based on capital letters or delimiters\n",
    "games_df = combined_games_df\n",
    "\n",
    "games_df_clean = games_df.copy()\n",
    "\n",
    "# Clean specific columns using .apply()\n",
    "games_df_clean['Released'] = games_df['Released'].apply(clean_released_date)\n",
    "games_df_clean['Critics'] = games_df['Critics'].apply(clean_value).apply(clean_critics)\n",
    "games_df_clean['Gameplay'] = games_df['Gameplay'].apply(lambda x: clean_and_split(x) if isinstance(x, str) else x)\n",
    "games_df_clean['Setting'] = games_df['Setting'].apply(lambda x: clean_and_split(x) if isinstance(x, str) else x)\n",
    "games_df_clean['Perspective'] = games_df['Perspective'].apply(lambda x: clean_and_split(x) if isinstance(x, str) else x)\n",
    "games_df_clean['Interface'] = games_df['Interface'].apply(lambda x: clean_and_split(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Split the 'Genre' column based on commas and remove extra spaces\n",
    "basic_games_df['Genre'] = basic_games_df['Genre'].apply(clean_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "sns.set_theme(style=\"ticks\", palette=\"colorblind\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combined_df = pd.concat([basic_games_df, games_df_clean], axis = 1)\n",
    "\n",
    "# Convert 'Year' column to categorical type\n",
    "all_combined_df['Year'] = all_combined_df['Year'].astype('category')\n",
    "\n",
    "# Convert the column 'Score' to numeric\n",
    "all_combined_df['Critics'] = pd.to_numeric(all_combined_df['Critics'], errors='coerce')\n",
    "\n",
    "\n",
    "# Count missing values for each column\n",
    "missing_values_per_column = all_combined_df.isna().sum()\n",
    "missing_values_per_column\n",
    "\n",
    "#ESRB+ and Multiplayer Options have too many missing values to be of worth; drop them\n",
    "all_combined_df = all_combined_df.drop(['ESRB Rating', 'Multiplayer Options'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to  csv\n",
    "all_combined_df.to_csv('games_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Barplot\n",
    "\n",
    "# List of month names\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "          'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "# Filter rows where 'Released' contains a month name\n",
    "barplot_data = all_combined_df[all_combined_df['Released'].str.contains('|'.join(month_order), na=False)]\n",
    "\n",
    "# Convert the 'Released' column to a categorical type with the defined order\n",
    "barplot_data['Released'] = pd.Categorical(barplot_data['Released'], categories=month_order, ordered=True)\n",
    "\n",
    "# Plotting the count plot with months in chronological order\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=barplot_data, x='Released', order=month_order)\n",
    "plt.title('Releases per Month')\n",
    "plt.xlabel('Release Month')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot\n",
    "\n",
    "# Explode the 'Genre' column to match each perspective with its corresponding 'Critics' score\n",
    "exploded_df = all_combined_df.explode('Genre').reset_index(drop = True)\n",
    "# .explode('Gameplay').explode('Interface').explode('Setting').explode('Genre')\n",
    "\n",
    "# Plot a box plot of Critics scores for each Perspective\n",
    "sns.set_theme(style=\"ticks\", palette=\"colorblind\")\n",
    "sns.boxplot(x='Genre', y='Score', data=exploded_df)\n",
    "plt.xticks(rotation=90)\n",
    "# plt.xlabel('Perspective')\n",
    "plt.ylabel('Moby Score')\n",
    "plt.title('Score by Genre Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stacked DataFrame\n",
    "\n",
    "# Group the data and create a stacked DataFrame\n",
    "exploded_df = all_combined_df.explode('Genre').reset_index(drop = True)\n",
    "data = exploded_df.groupby(['Year', 'Genre']).size().reset_index(name='Count')\n",
    "\n",
    "# Create the stacked area chart\n",
    "fig = px.area(data, x='Year', y='Count', color='Genre', \n",
    "              title='Games Released by Genre over Time',\n",
    "              labels={'Year': 'Year', 'Count': 'Number of Games'},\n",
    "              template='plotly')\n",
    "\n",
    "fig.update_layout(margin=dict(l=0, r=0, t=40, b=40))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stacked bar plot\n",
    "\n",
    "exploded_game_inter = all_combined_df.explode('Setting').explode('Perspective').reset_index(drop = True)\n",
    "\n",
    "# Pivot the data to create a stacked bar chart\n",
    "pivot_df = exploded_game_inter.groupby(['Setting', 'Perspective']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot stacked bar chart\n",
    "pivot_df.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "plt.title('Stacked Bar Plot: Setting and Perspective Comparison')\n",
    "plt.xlabel('Settings')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Score     Critics\n",
      "count  550.000000  550.000000\n",
      "mean     8.023273   84.336364\n",
      "std      0.257217    3.365087\n",
      "min      7.800000   77.000000\n",
      "25%      7.900000   82.000000\n",
      "50%      7.900000   84.000000\n",
      "75%      8.100000   86.000000\n",
      "max      9.400000   96.000000\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for all numeric columns\n",
    "\n",
    "numeric_summary = all_combined_df.describe()\n",
    "\n",
    "print(numeric_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat386",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
